{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60475be",
   "metadata": {},
   "source": [
    "# DS321: Computational Statistics <br>\n",
    "\n",
    "##   Laboratory Exercise: Univariate (Secant Method) and Multivariate Optimization (Introduction)\n",
    "\n",
    "University of Science and Technology of Southern Philippines <br>\n",
    "\n",
    "## Student Name: <code>Joear T. Berdon</code>\n",
    "\n",
    "\n",
    "Instructor: **Romen Samuel Wabina, MSc** <br>\n",
    "MSc Data Science and AI | Asian Institute of Technology <br>\n",
    "*ongoing* PhD Data Science (Healthcare and Clinical Informatics) \n",
    "\n",
    "\n",
    "### Instructions\n",
    "- Please submit this laboratory exercise as a **Jupyter Notebook file** <code>.ipynb</code> via email <code>romensamuelrodis.wab@student.mahidol.edu</code>\n",
    "- Always remember: I use GPTZero "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33361682",
   "metadata": {},
   "source": [
    "### <code>Question 1</code>: Modify the function <code>secant_method</code> by adding the tolerance value as a parameter in the function. Use the function to evaluate whether its number of iterations has decreased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c376637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891039e",
   "metadata": {},
   "source": [
    "Taking $f(x) = 2x^3 - x^2 +10x - 3 $ at initial values $x_0 = 2$ and $x_1 = 4$ with $tol=1e-6$, $max iterations = 10$ as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f3f6add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 1.5166666666666666\n",
      "Iteration 2: \t 1.200154503032644\n",
      "Iteration 3: \t 0.6014833604425738\n",
      "Iteration 4: \t 0.36834378672672496\n",
      "Iteration 5: \t 0.3064694836838134\n",
      "Iteration 6: \t 0.303638291005812\n",
      "Iteration 7: \t 0.30362066994048525\n",
      "Secant's method local optima: x =  0.3036206657641235\n"
     ]
    }
   ],
   "source": [
    "#setting the globals\n",
    "A = 2\n",
    "B = 4\n",
    "TOL = 10**-6\n",
    "N = 10\n",
    "\n",
    "#defining function\n",
    "def f(x):\n",
    "    return (2*math.pow(x,3)) - math.pow(x,2) + (10*x) - 3\n",
    "\n",
    "#secant method implementation\n",
    "def secant_method(f, x0, x1, tol, max_iter):\n",
    "    \n",
    "    for i in range(0,max_iter):\n",
    "        \n",
    "        #checks if the second term is undefined (zero denominator)\n",
    "        if f(x1) - f(x0) == 0:\n",
    "            print(\"Error!\")\n",
    "            break\n",
    "            \n",
    "        #Calculation\n",
    "        x2 = x1 - (f(x1) * (x1 - x0)) / float(f(x1) - f(x0))\n",
    "            \n",
    "        #Decide to repeat the steps \n",
    "        if abs(x2 - x1) < tol:\n",
    "            return x2\n",
    "        \n",
    "        print(f'Iteration {i+1}: \\t {x2}')\n",
    "        \n",
    "        #updating\n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "        \n",
    "    return \"The method failed after {} iterations\".format(N) \n",
    "\n",
    "#calling the method\n",
    "root = secant_method(f, A, B, TOL, N)\n",
    "print(\"Secant's method local optima: x = \", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35963f1e",
   "metadata": {},
   "source": [
    "After setting the **tolerance as a parameter** in the function, the number of iterations has decreased. It is because it satisfies the condition in which it will give <code>local optima if it's less than tolerance</code> rather than running all iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0f844",
   "metadata": {},
   "source": [
    "### <code>Question 2</code>: Evaluate the following equations on Secant method at 10 iterations using your modified Python function.\n",
    "- $f(x) = x^3 - x - 1$ at initial values $x_0 = 1$ and $x_1 = 2$.\n",
    "- $f(x) = \\cos{x} + 2\\sin{x} + x^2$ at initial values $x_0 = 0.001$ and $x_1 = 0.001$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985244fd",
   "metadata": {},
   "source": [
    "**1.** $f(x) = x^3 - x - 1$ at initial values $x_0 = 1$ and $x_1 = 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc2200a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 1.1666666666666665\n",
      "Iteration 2: \t 1.2531120331950207\n",
      "Iteration 3: \t 1.3372064458416564\n",
      "Iteration 4: \t 1.323850096387641\n",
      "Iteration 5: \t 1.324707936532088\n",
      "Iteration 6: \t 1.3247179653538177\n",
      "Secant's method local optima: x =  1.3247179572446703\n"
     ]
    }
   ],
   "source": [
    "#setting the globals\n",
    "A = 1\n",
    "B = 2\n",
    "TOL = 10**-6\n",
    "N = 10\n",
    "\n",
    "#defining function\n",
    "def f(x):\n",
    "    return math.pow(x,3) - x - 1\n",
    "\n",
    "#secant method implementation\n",
    "def secant_method(f, x0, x1, tol, max_iter):\n",
    "    \n",
    "    for i in range(0,max_iter):\n",
    "        \n",
    "        #checks if the second term is undefined (zero denominator)\n",
    "        if f(x1) - f(x0) == 0:\n",
    "            print(\"Error!\")\n",
    "            break\n",
    "            \n",
    "        #Calculation\n",
    "        x2 = x1 - (f(x1) * (x1 - x0)) / float(f(x1) - f(x0))\n",
    "            \n",
    "        #Decide to repeat the steps \n",
    "        if abs(x2 - x1) < tol:\n",
    "            return x2\n",
    "        \n",
    "        print(f'Iteration {i+1}: \\t {x2}')\n",
    "        \n",
    "        #updating\n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "        \n",
    "    return \"The method failed after {} iterations\".format(N) \n",
    "\n",
    "#calling the method\n",
    "root = secant_method(f, A, B, TOL, N)\n",
    "print(\"Secant's method local optima: x = \", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00962fe",
   "metadata": {},
   "source": [
    "**2.** $f(x) = \\cos{x} + 2\\sin{x} + x^2$ at initial values $x_0 = 0.001$ and $x_1 = 0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8769a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error!\n",
      "Secant's method local optima: x =  The method failed after 10 iterations\n"
     ]
    }
   ],
   "source": [
    "#setting the globals\n",
    "A = 0.001\n",
    "B = 0.001\n",
    "TOL = 10**-6\n",
    "N = 10\n",
    "\n",
    "#defining function\n",
    "def f(x):\n",
    "    return math.cos(x) - 2*math.sin(x) + math.pow(x,2)\n",
    "\n",
    "#secant method implementation\n",
    "def secant_method(f, x0, x1, tol, max_iter):\n",
    "    \n",
    "    for i in range(0,max_iter):\n",
    "        \n",
    "        #checks if the second term is undefined (zero denominator)\n",
    "        if f(x1) - f(x0) == 0:\n",
    "            print(\"Error!\")\n",
    "            break\n",
    "            \n",
    "        #Calculation\n",
    "        x2 = x1 - (f(x1) * (x1 - x0)) / float(f(x1) - f(x0))\n",
    "            \n",
    "        #Decide to repeat the steps \n",
    "        if abs(x2 - x1) < tol:\n",
    "            return x2\n",
    "        \n",
    "        print(f'Iteration {i+1}: \\t {x2}')\n",
    "        \n",
    "        #updating\n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "        \n",
    "    return \"The method failed after {} iterations\".format(N) \n",
    "\n",
    "#calling the method\n",
    "root = secant_method(f, A, B, TOL, N)\n",
    "print(\"Secant's method local optima: x = \", root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ac14ca",
   "metadata": {},
   "source": [
    "It will give an error kasi by solving the second term in the secant method, it's <code>denominator is equal to zero </code> resulting to undefined hence, it will not give local optima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f59a2a",
   "metadata": {},
   "source": [
    "### <code>Question 3</code>: Evaluate the following equations on Secant and Newton's method at 10 iterations. Create a function that prints the local optima of both methods and measure their difference. You can use the functions above. \n",
    "- $f(x) = x^2 - 2$ where $x_0 = 2$ as the initial guess for Newton's Method while $x_0 = 3$ and $x_1 = 2$ for the Secant Method\n",
    "- $f(x) = x^3 - 7x^2 + 8x - 3$ where $x_0 = 0.45$ as the initial guess for Newton's method while $x_0 = 1$ and $x_1 = 0.45$ for the Secant Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480ec90e",
   "metadata": {},
   "source": [
    "**1.** $f(x) = x^2 - 2$ where $x_0 = 2$ as the initial guess for Newton's Method while $x_0 = 3$ and $x_1 = 2$ for the Secant Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44697d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition\n",
    "def f(x):\n",
    "    return math.pow(x,2)-2\n",
    "\n",
    "#first derivative\n",
    "def fprime(x):\n",
    "    return (2 * x)\n",
    "\n",
    "#newtons implementation\n",
    "def newton(approx, max_iter):\n",
    "    a = approx\n",
    "    \n",
    "    for i in range(0, max_iter):\n",
    "        \n",
    "        #computation\n",
    "        y = f(a)/fprime(a)\n",
    "        b = a - y\n",
    "        \n",
    "        #checks if it has zero derivative\n",
    "        if fprime(a) == 0:\n",
    "            print(\"Error! f'(x) is undefined, no root found!\")\n",
    "            break\n",
    "            \n",
    "        #updating\n",
    "        a = b\n",
    "        print(f'Iteration {i+1}: \\t {b}')\n",
    "    return b\n",
    "\n",
    "#secant method implementation\n",
    "def secant_method(f, x0, x1, max_iter):\n",
    "    \n",
    "    for i in range(0,max_iter):\n",
    "        \n",
    "        #checks if the second term is undefined (zero denominator)\n",
    "        if f(x1) - f(x0) == 0:\n",
    "            print(\"Error!\")\n",
    "            break\n",
    "            \n",
    "        #Calculation\n",
    "        x2 = x1 - (f(x1) * (x1 - x0)) / float(f(x1) - f(x0))\n",
    "             \n",
    "        #updating\n",
    "        x0 = x1\n",
    "        x1 = x2\n",
    "        \n",
    "        print(f'Iteration {i+1}: \\t {x2}')\n",
    "    return x2\n",
    "\n",
    "def difference():\n",
    "    a= newton_root\n",
    "    b = secant_root\n",
    "    diff = abs(newton_root - secant_root)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7669c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 1.5\n",
      "Iteration 2: \t 1.4166666666666667\n",
      "Iteration 3: \t 1.4142156862745099\n",
      "Iteration 4: \t 1.4142135623746899\n",
      "Iteration 5: \t 1.4142135623730951\n",
      "Iteration 6: \t 1.414213562373095\n",
      "Iteration 7: \t 1.4142135623730951\n",
      "Iteration 8: \t 1.414213562373095\n",
      "Iteration 9: \t 1.4142135623730951\n",
      "Iteration 10: \t 1.414213562373095\n",
      "Newton's method local optima: x =  1.414213562373095\n"
     ]
    }
   ],
   "source": [
    "#calling the method for newton\n",
    "newton_root = newton(2, 10)\n",
    "print(\"Newton's method local optima: x = \", newton_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d60659c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 1.6\n",
      "Iteration 2: \t 1.4444444444444444\n",
      "Iteration 3: \t 1.416058394160584\n",
      "Iteration 4: \t 1.414233059257159\n",
      "Iteration 5: \t 1.4142135750814935\n",
      "Iteration 6: \t 1.4142135623731826\n",
      "Iteration 7: \t 1.414213562373095\n",
      "Iteration 8: \t 1.4142135623730951\n",
      "Iteration 9: \t 1.414213562373095\n",
      "Iteration 10: \t 1.414213562373095\n",
      "Secant's method local optima: x =  1.414213562373095\n"
     ]
    }
   ],
   "source": [
    "#calling the method for secant\n",
    "secant_root = secant_method(f, 3, 2, 10)\n",
    "print(\"Secant's method local optima: x = \", secant_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bbe47de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton's Method local optima:  1.414213562373095\n",
      "Secant Method local optima:  1.414213562373095\n",
      "Difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "D = difference()\n",
    "print(\"Newton's Method local optima: \", newton_root)\n",
    "print(\"Secant Method local optima: \", secant_root)\n",
    "print(\"Difference: \", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ac996",
   "metadata": {},
   "source": [
    "**2.** $f(x) = x^3 - 7x^2 + 8x - 3$ where $x_0 = 0.45$ as the initial guess for Newton's method while $x_0 = 1$ and $x_1 = 0.45$ for the Secant Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158ff198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function definition\n",
    "def f(x):\n",
    "    return math.pow(x,3) - 7*math.pow(x,2) + 8*x - 3\n",
    "\n",
    "#first derivative\n",
    "def fprime(x):\n",
    "    return 3 * math.pow(x,2) - (14 * x) + 8\n",
    "\n",
    "#newtons implementation\n",
    "def newton(approx, max_iter):\n",
    "    a = approx\n",
    "    \n",
    "    for i in range(0, max_iter):\n",
    "        \n",
    "        #computation\n",
    "        y = f(a)/fprime(a)\n",
    "        b = a - y\n",
    "        \n",
    "        #checks if it has zero derivative\n",
    "        if fprime(a) == 0:\n",
    "            print(\"Error! f'(x) is undefined, no root found!\")\n",
    "            break\n",
    "            \n",
    "        #updating\n",
    "        a = b\n",
    "        print(f'Iteration {i+1}: \\t {b}')\n",
    "    return b\n",
    "\n",
    "#secant method implementation\n",
    "def secant_method(f, x0, x1, max_iter):\n",
    "    \n",
    "    for i in range(0,max_iter):\n",
    "        \n",
    "        #checks if the second term is undefined (zero denominator)\n",
    "        if f(x1) - f(x0) == 0:\n",
    "            print(\"Error!\")\n",
    "            break\n",
    "            \n",
    "        #Calculation\n",
    "        x2 = x1 - (f(x1) * (x1 - x0)) / float(f(x1) - f(x0))\n",
    "             \n",
    "        #updating\n",
    "        x0, x1 = x1, x2\n",
    "        \n",
    "        print(f'Iteration {i+1}: \\t {x2}')\n",
    "    return x2\n",
    "\n",
    "def difference():\n",
    "    a= newton_root\n",
    "    b = secant_root\n",
    "    diff = abs(newton_root - secant_root)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56280e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t 0.7647887323943662\n",
      "Iteration 2: \t 0.2096527279903404\n",
      "Iteration 3: \t 0.5216267176184952\n",
      "Iteration 4: \t 0.911261310664203\n",
      "Iteration 5: \t 0.5732987502857287\n",
      "Iteration 6: \t 1.1211897712246115\n",
      "Iteration 7: \t 0.7593116146928851\n",
      "Iteration 8: \t 0.17798419674703692\n",
      "Iteration 9: \t 0.49784048712938106\n",
      "Iteration 10: \t 0.8523426445442217\n",
      "Newton's method local optima: x =  0.8523426445442217\n"
     ]
    }
   ],
   "source": [
    "#calling the method for newton\n",
    "newton_root = newton(0.45, 10)\n",
    "print(\"Newton's method local optima: x = \", newton_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f05c41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: \t -1.0100502512562815\n",
      "Iteration 2: \t 0.5072465811609521\n",
      "Iteration 3: \t 0.557113720492756\n",
      "Iteration 4: \t 0.9449021363844228\n",
      "Iteration 5: \t -0.13481905240473768\n",
      "Iteration 6: \t 1.2169884993018618\n",
      "Iteration 7: \t 2.2562543492733096\n",
      "Iteration 8: \t 0.9555083622238383\n",
      "Iteration 9: \t 0.8171942165462645\n",
      "Iteration 10: \t 0.5283409088722151\n",
      "Secant's method local optima: x =  0.5283409088722151\n"
     ]
    }
   ],
   "source": [
    "#calling the method for secant\n",
    "secant_root = secant_method(f, 1, 0.45, 10)\n",
    "print(\"Secant's method local optima: x = \", secant_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41152e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newton's Method local optima:  0.8523426445442217\n",
      "Secant Method local optima:  0.5283409088722151\n",
      "Difference:  0.32400173567200663\n"
     ]
    }
   ],
   "source": [
    "D = difference()\n",
    "print(\"Newton's Method local optima: \", newton_root)\n",
    "print(\"Secant Method local optima: \", secant_root)\n",
    "print(\"Difference: \", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c215ddd",
   "metadata": {},
   "source": [
    "## Multivariate Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ee46f",
   "metadata": {},
   "source": [
    "Using the function <code>get_critical_points</code>, evaluate the following functions below by classifying the critical points whether they are local minima, local maxima, saddle points, or the function is inconclusive. You can create a Python function to solve this.\n",
    "- $f(x,y) = x^2+2xy+4y^2+5x-6y$\n",
    "- $f(x,y) = -x^2 - y^2$\n",
    "- $f(a, b) = a^2 + 3a^2 - 9a + b^2 - 12b$\n",
    "- $f(r, s) = 3rs - r^2 - s^2$\n",
    "- $f(c, d) = x^2 + y^2 + 2x + 6y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f907cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3080aae",
   "metadata": {},
   "source": [
    "- $f(x,y) = x^2+2xy+4y^2+5x-6y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82e71981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical point: {x: -13/3, y: 11/6}\n",
      "Hessian Matrix:\n",
      " [[2. 2.]\n",
      " [2. 8.]] \n",
      "Determinant: 12.0 \n",
      "f_xx: 2.0 \n",
      "Classification: Local Minimum \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the variables\n",
    "x, y = sympy.symbols('x, y')\n",
    "\n",
    "#function\n",
    "f = x**2 + (2*x*y) + (4*y**2) + 5*x - 6*y\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    \n",
    "    #this is where we get the partial derivatives of the function (f) with respect to each variable in (variables) \n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "\n",
    "    #hessian matrix\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    H = H.astype('float')\n",
    "    \n",
    "    #solving critical point\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    \n",
    "    #solving determinant\n",
    "    determinant = np.linalg.det(H)\n",
    "    \n",
    "    #classification\n",
    "    if determinant > 0 and H[0,0] > 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Minimum\"\n",
    "    elif determinant > 0 and H[0,0] < 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Maximum\"\n",
    "    elif determinant == 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Inconclusive\"\n",
    "    else:\n",
    "        return crit_points, H, determinant, H[0,0], \"Saddle point\"\n",
    "\n",
    "\n",
    "#calling the method\n",
    "critical_point, Hessian, det, fxx, classification = get_critical_points(f, [x, y])\n",
    "\n",
    "print(f\"Critical point: {critical_point}\\nHessian Matrix:\\n {Hessian} \\nDeterminant: {det} \\nf_xx: {fxx} \\nClassification: {classification} \\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9955bc",
   "metadata": {},
   "source": [
    "- $f(x,y) = -x^2 - y^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531c8ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical point: {x: 0, y: 0}\n",
      "Hessian Matrix:\n",
      " [[-2.  0.]\n",
      " [ 0. -2.]] \n",
      "Determinant: 4.0 \n",
      "f_xx: -2.0 \n",
      "Classification: Local Maximum \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the variables\n",
    "x, y = sympy.symbols('x, y')\n",
    "\n",
    "#function\n",
    "f = (-x**2) - (y**2)\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    \n",
    "    #this is where we get the partial derivatives of the function (f) with respect to each variable in (variables) \n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "\n",
    "    #hessian matrix\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    H = H.astype('float')\n",
    "    \n",
    "    #solving critical point\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    \n",
    "    #solving determinant\n",
    "    determinant = np.linalg.det(H)\n",
    "    \n",
    "    #classification\n",
    "    if determinant > 0 and H[0,0] > 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Minimum\"\n",
    "    elif determinant > 0 and H[0,0] < 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Maximum\"\n",
    "    elif determinant == 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Inconclusive\"\n",
    "    else:\n",
    "        return crit_points, H, determinant, H[0,0], \"Saddle point\"\n",
    "\n",
    "#calling the method\n",
    "critical_point, Hessian, det, fxx, classification = get_critical_points(f, [x, y])\n",
    "\n",
    "print(f\"Critical point: {critical_point}\\nHessian Matrix:\\n {Hessian} \\nDeterminant: {det} \\nf_xx: {fxx} \\nClassification: {classification} \\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d65570c",
   "metadata": {},
   "source": [
    "- $f(a, b) = a^2 + 3a^2 - 9a + b^2 - 12b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72505da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical point: {x: 9/8, y: 6}\n",
      "Hessian Matrix:\n",
      " [[8. 0.]\n",
      " [0. 2.]] \n",
      "Determinant: 15.999999999999998 \n",
      "f_xx: 8.0 \n",
      "Classification: Local Minimum \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the variables\n",
    "a, b = sympy.symbols('x, y')\n",
    "\n",
    "#function\n",
    "f = x**2 +(3*x**2) - 9*x + y**2 - 12*y\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    \n",
    "    #this is where we get the partial derivatives of the function (f) with respect to each variable in (variables) \n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "\n",
    "    #hessian matrix\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    H = H.astype('float')\n",
    "    \n",
    "    #solving critical point\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    \n",
    "    #solving determinant\n",
    "    determinant = np.linalg.det(H)\n",
    "    \n",
    "    #classification\n",
    "    if determinant > 0 and H[0,0] > 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Minimum\"\n",
    "    elif determinant > 0 and H[0,0] < 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Maximum\"\n",
    "    elif determinant == 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Inconclusive\"\n",
    "    else:\n",
    "        return crit_points, H, determinant, H[0,0], \"Saddle point\"\n",
    "\n",
    "#calling the method\n",
    "critical_point, Hessian, det, fxx, classification = get_critical_points(f, [x, y])\n",
    "\n",
    "print(f\"Critical point: {critical_point}\\nHessian Matrix:\\n {Hessian} \\nDeterminant: {det} \\nf_xx: {fxx} \\nClassification: {classification} \\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d233dc6",
   "metadata": {},
   "source": [
    "- $f(r, s) = 3rs - r^2 - s^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13ae5b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical point: {r: 0, s: 0}\n",
      "Hessian Matrix:\n",
      " [[-2.  3.]\n",
      " [ 3. -2.]] \n",
      "Determinant: -5.000000000000001 \n",
      "f_xx: -2.0 \n",
      "Classification: Saddle point \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the variables\n",
    "x, y = sympy.symbols('r, s')\n",
    "\n",
    "#function\n",
    "f = 3*r*s - r**2 - s**2\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    \n",
    "    #this is where we get the partial derivatives of the function (f) with respect to each variable in (variables) \n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "\n",
    "    #hessian matrix\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    H = H.astype('float')\n",
    "    \n",
    "    #solving critical point\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    \n",
    "    #solving determinant\n",
    "    determinant = np.linalg.det(H)\n",
    "    \n",
    "    #classification\n",
    "    if determinant > 0 and H[0,0] > 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Minimum\"\n",
    "    elif determinant > 0 and H[0,0] < 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Maximum\"\n",
    "    elif determinant == 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Inconclusive\"\n",
    "    else:\n",
    "        return crit_points, H, determinant, H[0,0], \"Saddle point\"\n",
    "\n",
    "#calling the method\n",
    "critical_point, Hessian, det, fxx, classification = get_critical_points(f, [x, y])\n",
    "\n",
    "print(f\"Critical point: {critical_point}\\nHessian Matrix:\\n {Hessian} \\nDeterminant: {det} \\nf_xx: {fxx} \\nClassification: {classification} \\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5343bd1d",
   "metadata": {},
   "source": [
    "- $f(c, d) = x^2 + y^2 + 2x + 6y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20f9469e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical point: {x: -1, y: -3}\n",
      "Hessian Matrix:\n",
      " [[2. 0.]\n",
      " [0. 2.]] \n",
      "Determinant: 4.0 \n",
      "f_xx: 2.0 \n",
      "Classification: Local Minimum \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#defining the variables\n",
    "x, y = sympy.symbols('x, y')\n",
    "\n",
    "#function\n",
    "f = x**2 + y**2 + 2*x + 6*y\n",
    "\n",
    "def get_critical_points(f, variables):\n",
    "    \n",
    "    #this is where we get the partial derivatives of the function (f) with respect to each variable in (variables) \n",
    "    df = [sympy.diff(f, x) for x in variables]\n",
    "\n",
    "    #hessian matrix\n",
    "    H = np.array([[sympy.diff(df[i], x) for x in variables] for i in range(len(variables))])\n",
    "    H = H.astype('float')\n",
    "    \n",
    "    #solving critical point\n",
    "    crit_points = sympy.solve(df, variables)\n",
    "    \n",
    "    #solving determinant\n",
    "    determinant = np.linalg.det(H)\n",
    "    \n",
    "    #classification\n",
    "    if determinant > 0 and H[0,0] > 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Minimum\"\n",
    "    elif determinant > 0 and H[0,0] < 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Local Maximum\"\n",
    "    elif determinant == 0:\n",
    "        return crit_points, H, determinant, H[0,0], \"Inconclusive\"\n",
    "    else:\n",
    "        return crit_points, H, determinant, H[0,0], \"Saddle point\"\n",
    "\n",
    "#calling the method\n",
    "critical_point, Hessian, det, fxx, classification = get_critical_points(f, [x, y])\n",
    "\n",
    "print(f\"Critical point: {critical_point}\\nHessian Matrix:\\n {Hessian} \\nDeterminant: {det} \\nf_xx: {fxx} \\nClassification: {classification} \\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1353ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
